{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "---\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    "    1. MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    "\n",
    "    2. Normalize data by rescaling them to (0,1)\n",
    "\n",
    "    3. Convert label arrays to 1-hot representation (keras.utils.to_categorical)\n",
    "\n",
    "    4. Define Model\n",
    "\n",
    "        - Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "        - Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "        - Output Layer: Fully Connected + Softmax Activition\n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Flatten()\n",
    "    5. Dense(128, activation='relu')\n",
    "    6. Dense(num_classes, activation='softmax')\n",
    "\n",
    "- Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Packages \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting the digit image\n",
    "%matplotlib inline  \n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data and Splitting into Test and Train \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the random image and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "rand_num = np.random.randint(60000)\n",
    "\n",
    "plt.imshow(X_train[rand_num], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# print its label\n",
    "print('label:', y_train[rand_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network accept 1D data. So we need to flatten our 2D image, then print the dimension of the result arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data \n",
    "# NOTE: when data is big it is better to do reshaping and normalinzing inplace, bc copying the opject takes up a lot\n",
    "# of memory space\n",
    "X_train_reshaped = np.reshape(X_train, [-1, 28*28])\n",
    "X_test_reshaped = np.reshape(X_test, [-1, 28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data by rescaling them to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normal = X_train_reshaped / np.max(X_train_reshaped)\n",
    "X_test_normal = X_test_reshaped / np.max(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert label arrays to 1-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train, 10)\n",
    "y_test_one_hot = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the following layers to the network:\n",
    "\n",
    "- Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "- Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "- Outout Layer: Fully Connected + Softmax Activition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Sequential()\n",
    "# Add the layers to model here.\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer=RandomNormal(0,0.01)))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer=RandomNormal(0,0.01)))\n",
    "# Output Layer: Fully Connected + Softmax Activition\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=RandomNormal(0,0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine loss function, optimizer and metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the review of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Here we saved the raw model without any training. we will use it later.\n",
    "model.save('raw_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, 10)\n",
    "y_test_one_hot = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0xb45a002e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0xb45a002b0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0xb45a00080>,\n",
       " <keras.layers.core.Flatten at 0xb457d3be0>,\n",
       " <keras.layers.core.Dense at 0xb457d3860>,\n",
       " <keras.layers.core.Dense at 0xb459ce7f0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_complex.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "# 2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "# 3. MaxPooling2D(pool_size=(2, 2))\n",
    "# 4. Flatten()\n",
    "# 5. Dense(128, activation='relu')\n",
    "# 6. Dense(num_classes, activation='softmax')\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "model_complex = Sequential()\n",
    "model_complex.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n",
    "model_complex.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model_complex.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_complex.add(Flatten())\n",
    "model_complex.add(Dense(128, activation='relu'))\n",
    "model_complex.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complex.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.1145 - acc: 0.9651 - val_loss: 0.0444 - val_acc: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb5fe51898>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_complex.fit(X_train, y_train_one_hot, validation_data=(X_test, y_test_one_hot), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
