{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Part 1\n",
    "---\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    "    1. MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    "\n",
    "    2. Normalize data by rescaling them to (0,1)\n",
    "\n",
    "    3. Convert label arrays to 1-hot representation (keras.utils.to_categorical)\n",
    "\n",
    "    4. Define Model\n",
    "\n",
    "        - Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "        - Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "        - Output Layer: Fully Connected + Softmax Activition\n",
    "\n",
    "- Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Packages \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting the digit image\n",
    "%matplotlib inline  \n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the random image and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 3\n"
     ]
    }
   ],
   "source": [
    "rand_num = np.random.randint(60000)\n",
    "\n",
    "plt.imshow(X_train[rand_num], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# print its label\n",
    "print('label:', y_train[rand_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network accept 1D data. So we need to flatten our 2D image, then print the dimension of the result arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, Normalizing, one-hot-coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data \n",
    "# NOTE: when data is big it is better to do reshaping and normalinzing inplace, bc copying the opject takes up a lot\n",
    "# of memory space\n",
    "NUM_CLASSES = 10\n",
    "X_train = np.reshape(X_train, [-1, 28*28]).astype('float32')\n",
    "X_test = np.reshape(X_test, [-1, 28*28]).astype('float32')\n",
    "\n",
    "# Normalize data by rescaling them to (0,1)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Convert label arrays to 1-hot representation\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the following layers to the network:\n",
    "\n",
    "- Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "- Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "- Outout Layer: Fully Connected + Softmax Activition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Sequential()\n",
    "# Add the layers to model here.\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer=RandomNormal(0,0.01)))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer=RandomNormal(0,0.01)))\n",
    "# Output Layer: Fully Connected + Softmax Activition\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=RandomNormal(0,0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine loss function, optimizer and metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.3062 - acc: 0.9052 - val_loss: 0.1593 - val_acc: 0.9537\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1008 - acc: 0.9691 - val_loss: 0.1301 - val_acc: 0.9595\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0660 - acc: 0.9794 - val_loss: 0.0776 - val_acc: 0.9776\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0489 - acc: 0.9844 - val_loss: 0.0753 - val_acc: 0.9787\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0783 - val_acc: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb485fdf98>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the review of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
