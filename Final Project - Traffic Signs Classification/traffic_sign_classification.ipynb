{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic signs tutorial: https://chsasank.github.io/keras-tutorial.html <br/>\n",
    "what is that pet: https://www.udemy.com/deeplearning/learn/lecture/6798970#overview <br/>\n",
    "traffic signs on medium tutorial: https://towardsdatascience.com/recognizing-traffic-signs-with-over-98-accuracy-using-deep-learning-86737aedc2ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem I am tackling in this assignment is The German Traffic Sign Recognition Benchamark ([GTSRB](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news)).\n",
    "- The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n",
    "\n",
    "    - Single-image, multi-class classification problem\n",
    "    - More than 40 classes\n",
    "    - More than 50,000 images in total\n",
    "    - Large, lifelike database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tackling the problem and brainstorming\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My approach to solve this problem will be a CNN as it's very successful and most commonly applied to analyzing visual imagery.  \n",
    "- The tools will be used:\n",
    "    - Keras\n",
    "    - Convelutional Neural Network(CNN)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prerocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was donwloaded from the [GTSRB](https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/published-archive.html) website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As I the images vary in size and color lets do [histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization) in `HSV` color space and resize the images to a standard size. **This method usually increases the global contrast of many images, especially when the usable data of the image is represented by close contrast values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HSV = rgb2hsv( RGB ) converts the red, green, and blue values of an RGB image to hue, saturation, and value (HSV) values of an HSV image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import color, exposure, transform\n",
    "\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 48\n",
    "\n",
    "\n",
    "def preprocess_img(img):\n",
    "    # Histogram normalization in v channel\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central square crop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0] // 2, img.shape[1] // 2\n",
    "    img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,\n",
    "              centre[1] - min_side // 2:centre[1] + min_side // 2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img, -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:275: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:283: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:279: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 2. + (arr[idx, 2] - arr[idx, 0]) / delta[idx]\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "\n",
    "root_dir = '../Datasets/GTSRB/Final_Training/Images/'\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    img = preprocess_img(io.imread(img_path))\n",
    "    label = get_class(img_path)\n",
    "    imgs.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "X = np.array(imgs, dtype='float32')\n",
    "# Make one hot targets\n",
    "Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "- Let’s now define our models. We’ll use feed forward network with 6 convolutional layers followed by a fully connected hidden layer. We’ll also use dropout layers in between. Dropout regularizes the networks, i.e. it prevents the network from overfitting.\n",
    "\n",
    "- All our layers have relu activations except the output layer. Output layer uses softmax activation as it has to output the probability for each of the classes.\n",
    "\n",
    "- Sequential is a keras container for linear stack of layers. Each of the layers in the model needs to know the input shape it should expect, but it is enough to specify input_shape for the first layer of the Sequential model. Rest of the layers do automatic shape inference.\n",
    "\n",
    "- To attach a fully connected layer (aka dense layer) to a convolutional layer, we will have to reshape/flatten the output of the conv layer. This is achieved by Flatten layer\n",
    "\n",
    "- Go through the documentation of keras (relevant documentation : here and here) to understand what parameters for each of the layers mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "# let's train the model using SGD + momentum\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                     ModelCheckpoint('model.h5', save_best_only=True)]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
