{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic signs tutorial: https://chsasank.github.io/keras-tutorial.html <br/>\n",
    "what is that pet: https://www.udemy.com/deeplearning/learn/lecture/6798970#overview <br/>\n",
    "traffic signs on medium tutorial: https://towardsdatascience.com/recognizing-traffic-signs-with-over-98-accuracy-using-deep-learning-86737aedc2ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem I am tackling in this assignment is The German Traffic Sign Recognition Benchamark ([GTSRB](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news)).\n",
    "- The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n",
    "\n",
    "    - Single-image, multi-class classification problem\n",
    "    - More than 40 classes\n",
    "    - More than 50,000 images in total\n",
    "    - Large, lifelike database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tackling the problem and brainstorming\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My approach to solve this problem will be a CNN as it's very successful and most commonly applied to analyzing visual imagery.  \n",
    "- The tools will be used:\n",
    "    - Keras\n",
    "    - Convelutional Neural Network(CNN)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was donwloaded from the [GTSRB](https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/published-archive.html) website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As I the images vary in size and color lets do [histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization) in `HSV` color space and resize the images to a standard size. **This method usually increases the global contrast of many images, especially when the usable data of the image is represented by close contrast values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HSV = rgb2hsv( RGB ) converts the red, green, and blue values of an RGB image to hue, saturation, and value (HSV) values of an HSV image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from time import time\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization #, Merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "#     hsv = color.rgb2hsv(img)\n",
    "#     hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "#     img = color.hsv2rgb(hsv)\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "    \n",
    "    # rescale to standard size  \n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    # 注意对于tensorflow和theano通道顺序的不同\n",
    "    # roll color axis to axis 0\n",
    "    #img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all training images into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images from X.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with  h5py.File('X.h5') as hf: \n",
    "        X, Y = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from X.h5\")\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")\n",
    "    root_dir = 'data/Final_Training/Images/'\n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "    #打乱图片路径顺序\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))\n",
    "            \n",
    "            # io.imread 读入的数据是 uint8\n",
    "            \n",
    "            label = get_class(img_path)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "    # Y = ***[labels] 生成one-hot编码的方式\n",
    "    with h5py.File('X.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images from X_test.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with h5py.File('X_test.h5') as hf: \n",
    "        X_test, y_test = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from X_test.h5\")\n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")\n",
    "    import pandas as pd\n",
    "    test = pd.read_csv('data/Final_Test/Images/GT-final_test.csv',sep=';')\n",
    "\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    i = 0\n",
    "    for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "        img_path = os.path.join('data/Final_Test/Images/',file_name)\n",
    "        X_test.append(preprocess_img(io.imread(img_path)))\n",
    "        y_test.append(class_id)\n",
    "\n",
    "    X_test = np.array(X_test, dtype='float32')\n",
    "    y_test = np.array(y_test, dtype='uint8')\n",
    "\n",
    "    with h5py.File('X_test.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X_test)\n",
    "        hf.create_dataset('labels', data=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (37902, 3, 48, 48)\n",
      "Train labels shape:  (37902,)\n",
      "Validation data shape:  (1307, 3, 48, 48)\n",
      "Validation labels shape:  (1307,)\n",
      "Test data shape:  (39209, 3, 48, 48)\n",
      "Test labels shape:  (39209,)\n"
     ]
    }
   ],
   "source": [
    "index=np.zeros(1307, dtype='int')\n",
    "for i in range(1307):\n",
    "    index[i]=i*30+np.random.randint(0,30) \n",
    "\n",
    "X_validation = X[index]\n",
    "y_validation = Y[index]\n",
    "# X_val.shape\n",
    "# create the training index1\n",
    "index1=np.setdiff1d(np.array(range(39209)), index, assume_unique=True)\n",
    "X_train=X[index1]\n",
    "y_train=Y[index1]\n",
    "\n",
    "normalize = 0\n",
    "# Normalize the data: subtract the mean image\n",
    "if normalize:\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_validation.shape)\n",
    "print('Validation labels shape: ', y_validation.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "- Let’s now define our models. We’ll use feed forward network with 6 convolutional layers followed by a fully connected hidden layer. We’ll also use dropout layers in between. Dropout regularizes the networks, i.e. it prevents the network from overfitting.\n",
    "\n",
    "- All our layers have relu activations except the output layer. Output layer uses softmax activation as it has to output the probability for each of the classes.\n",
    "\n",
    "- Sequential is a keras container for linear stack of layers. Each of the layers in the model needs to know the input shape it should expect, but it is enough to specify input_shape for the first layer of the Sequential model. Rest of the layers do automatic shape inference.\n",
    "\n",
    "- To attach a fully connected layer (aka dense layer) to a convolutional layer, we will have to reshape/flatten the output of the conv layer. This is achieved by Flatten layer\n",
    "\n",
    "- Go through the documentation of keras (relevant documentation : here and here) to understand what parameters for each of the layers mean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
