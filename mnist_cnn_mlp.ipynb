{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_cnn_mlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sukhrobjon/DS-2.2-DL/blob/master/mnist_cnn_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIJWo6ZQpEnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# - Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset\n",
        "#     1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
        "#     2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
        "#     3. MaxPooling2D(pool_size=(2, 2))\n",
        "#     4. Flatten()\n",
        "#     5. Dense(128, activation='relu')\n",
        "#     6. Dense(num_classes, activation='softmax')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jdkfu5FzsVT",
        "colab_type": "code",
        "outputId": "3d40e96d-c9e3-4a4f-e048-12ff6aba7327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # for plotting the digit image\n",
        "%matplotlib inline  \n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import RandomNormal"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUiDONiJzyfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d0b8e22-5226-4cef-ad9a-6fed78bd12d2"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n",
        "\n",
        "# nora=malizing \n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# \n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPm9vxkFz98K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "model_complex = Sequential()\n",
        "model_complex.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n",
        "model_complex.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model_complex.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_complex.add(Flatten())\n",
        "model_complex.add(Dense(128, activation='relu'))\n",
        "model_complex.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04oOnbIr0JfL",
        "colab_type": "code",
        "outputId": "f47da8d8-a3b9-4051-c646-5e06e6371cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model_complex.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_complex.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0620 20:48:46.768857 140171681568640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0620 20:48:46.834048 140171681568640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.1149 - acc: 0.9652 - val_loss: 0.0476 - val_acc: 0.9849\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0385 - acc: 0.9878 - val_loss: 0.0323 - val_acc: 0.9898\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0344 - val_acc: 0.9887\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0511 - val_acc: 0.9870\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0125 - acc: 0.9959 - val_loss: 0.0399 - val_acc: 0.9886\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0413 - val_acc: 0.9894\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0438 - val_acc: 0.9888\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0501 - val_acc: 0.9898\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0517 - val_acc: 0.9882\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0540 - val_acc: 0.9892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7bf9389be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DcAQr_y1fD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}